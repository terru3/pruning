{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5202ad22-3c0d-4105-a252-bdc13e42faae",
   "metadata": {},
   "source": [
    "# Deconstructing LTH (CIFAR-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bff258-5809-4b7c-84c9-690c12facd37",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1905.01067"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2910dd5a-c902-4026-89c4-dd03a97fd83f",
   "metadata": {},
   "source": [
    "# TODO: implement \"large final same sign\" criteria, \"freeze_init_zero_all\" actions, compare w/ vanilla LTH iterative magnitude pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b82881-f26b-4e99-8b75-9d43dd440bff",
   "metadata": {},
   "source": [
    "# as of now, nothing has been edited. below is identical to vanilla pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cf368c-b887-46de-8afe-f6273fae1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0e47a5-ef43-4648-a0be-b3c321766a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = None\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9621ac8-e70f-46bd-9a94-aa3dfb246a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15037760-5e85-4e1e-a228-ebb01f954baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "path = path if drive is None else \"/content/drive/MyDrive/self-learn/pruning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c53a791-c468-4836-838b-679842573e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e210a94-77eb-434d-9174-4e591d016470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from constants import *\n",
    "from utils import (\n",
    "    set_seed,\n",
    "    train_data,\n",
    "    val_data,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    fine_labels,\n",
    "    invTrans,\n",
    ")\n",
    "from models import get_model_and_optimizer\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f847281-6cdb-4269-9fdf-57975d4aa9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: CNN_CIFAR_100_PRUNE_PCT_80\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = f\"CNN_CIFAR_100_PRUNE_PCT_{PRUNE_PCT}\"\n",
    "print(\"Model Name:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "404fa4d3-2a09-4f14-8d54-6a20abbc7c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL_NAME = f\"CNN_CIFAR_100_PRUNE_PCT_0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80708e66-0e2f-4db2-82ec-b46d802f0ca3",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7920c1c4-6133-4ae8-b3c5-7432b769060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # expected: (BATCH_SIZE, 3, 32, 32), picture of mountain\n",
    "\n",
    "# batch = next(iter(train_loader))\n",
    "# print(batch[0].shape)\n",
    "# test_idx = 42\n",
    "# plt.imshow(batch[0][test_idx].permute(1,2,0))\n",
    "# plt.title(f'{fine_labels[batch[1][test_idx]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b42b08-84c7-47b6-a81d-09f66f414db0",
   "metadata": {},
   "source": [
    "# Pruning utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeff347f-6714-42d1-a114-41358b75b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(m):\n",
    "    \"\"\"\n",
    "    Initializes params for model `m` given Conv2d, BatchNorm1d,  BatchNorm2d, Linear layers.\n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.normal_(m.weight.data, mean=1, std=0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        nn.init.normal_(m.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf0ddb3-69d4-4589-971f-1888f77ee23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_params(model, mask, init_state):\n",
    "    \"\"\"\n",
    "    Resets surviving model parameters to initial values\n",
    "    \"\"\"\n",
    "    step = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            param.data = torch.from_numpy(\n",
    "                init_state[name].cpu().numpy() * mask[step]\n",
    "            ).to(param.device)\n",
    "            step += 1\n",
    "        if \"bias\" in name:\n",
    "            param.data = init_state[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb6f466f-7324-4678-a98a-f792571093fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_init_mask(model):\n",
    "    \"\"\"\n",
    "    Generates initial mask matching the shape of model parameters.\n",
    "    Returns:\n",
    "        -Mask: List of length matching the number of weight layers in `m`, each of shape matching the corresponding weight tensor.\n",
    "    \"\"\"\n",
    "    weight_params = [\n",
    "        param.data.cpu().numpy()\n",
    "        for (name, param) in model.named_parameters()\n",
    "        if \"weight\" in name\n",
    "    ]\n",
    "    # TODO: maybe don't do this——could be unnecessarily memory intensive?\n",
    "    # if so, revert back to prev method: sum of weight in name to get the length, then down below loop through actual model\n",
    "    mask = [None] * len(weight_params)\n",
    "\n",
    "    step = 0\n",
    "    for param in weight_params:\n",
    "        mask[step] = np.ones_like(param)\n",
    "        step = step + 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da1b8b19-cfd6-4f0a-838c-b3a287faf97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_weight_names(model):\n",
    "    \"\"\"\n",
    "    Returns a list of weight layer names of model `m`.\n",
    "    \"\"\"\n",
    "    layer_weight_names = []\n",
    "    for name, _ in model.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            layer_weight_names.append(name.split(\".weight\")[0])\n",
    "    return layer_weight_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "370a251a-883c-4341-9b10-6ff69858ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_weight_params_by_layer(mask):\n",
    "    \"\"\"\n",
    "    Returns number of surviving (nonzero) weight parameters in a pruned model via its binary mask, by layer.\n",
    "    \"\"\"\n",
    "    return [np.count_nonzero(mask[i]) for i in range(len(mask))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8054d353-b695-4d50-bc88-f4b3a6f039d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_by_percent(model, mask, pct):\n",
    "    \"\"\"\n",
    "    Prunes `pct`% of parameters of model `m`, and modifies the pruning mask in-place as well.\n",
    "    Specifically, this is done layerwise (p% of weights for each layer).\n",
    "    \"\"\"\n",
    "    assert (\n",
    "        isinstance(pct, (int, float)) and 0 <= pct and pct <= 100\n",
    "    ), \"`pct` must be a numeric value between 0 and 100 (inclusive).\"\n",
    "    step = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            p_data_all = param.data.cpu().numpy()\n",
    "            # flattened nonzero weights\n",
    "            p_data = p_data_all[np.nonzero(p_data_all)]\n",
    "\n",
    "            cutoff_val = np.percentile(\n",
    "                np.abs(p_data), pct\n",
    "            )  # percentile calculated on surviving params\n",
    "            new_mask = np.where(np.abs(p_data_all) <= cutoff_val, 0, mask[step])\n",
    "            param.data = torch.from_numpy(p_data_all * new_mask).to(param.device)\n",
    "            mask[step] = new_mask\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfdb737-4c9c-452f-b531-3ee91c8eec46",
   "metadata": {},
   "source": [
    "# todo to modify prune fn above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdceea9d-4bc2-43bd-8939-c62a1a86e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "## large_final_same_sign:\n",
    "\n",
    "#         init_sign = np.sign(raw_initial_weights)\n",
    "#         final_sign = np.sign(raw_final_weights)\n",
    "#         diff_sign_ind = np.squeeze(np.where(init_sign != final_sign))\n",
    "#         cumulative_helped = np.abs(raw_final_weights)\n",
    "#         cumulative_helped[diff_sign_ind] = 0 # prune out weights which changed sign during training\n",
    "#         cumulative_helped = split_and_shape(cumulative_helped, shapes) # ignore the fn idc\n",
    "\n",
    "#         for i, pp in enumerate(prune_percentiles):\n",
    "#             if i % 2 == 1:\n",
    "#                 mask_values[i] = current_mask[i] # idk. maybe every other layer is bias so they ignore?\n",
    "#             else:\n",
    "#                 mask_values[i] = get_mask_by_layer_by_weight(cumulative_helped[i], pp, current_mask[i])\n",
    "\n",
    "# def get_mask_by_layer_by_weight(weight_one_layer, percentile, cur_mask = None):\n",
    "# layer_shape = weight_one_layer.shape\n",
    "# weight_one_layer = weight_one_layer.flatten()\n",
    "\n",
    "# if cur_mask is not None:\n",
    "#     cur_mask = cur_mask.flatten()\n",
    "#     #if something is already masked out, set it to a high number to avoid pruning again\n",
    "#     weight_one_layer[cur_mask == 0] = 9999\n",
    "# else:\n",
    "#     cur_mask = np.ones(weight_one_layer.shape)\n",
    "\n",
    "# prune_num = np.int(np.sum(cur_mask) * percentile / 100)\n",
    "# weight_ind = np.lexsort((np.random.random(weight_one_layer.size), weight_one_layer))[:prune_num]\n",
    "\n",
    "# cur_mask[weight_ind] = 0\n",
    "\n",
    "# return cur_mask.reshape(layer_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cab89e-b5e7-417a-a9e2-550527d47f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # freeze_init_zero_all\n",
    "\n",
    "#         freeze_init_value = initial_weights[:]\n",
    "#         for i in range(len(initial_weights)):\n",
    "#             temp = freeze_init_value[i].flatten()\n",
    "#             init_temp = np.abs(initial_weights[i].flatten())\n",
    "#             final_temp = np.abs(final_weights[i].flatten())\n",
    "#             temp[np.squeeze(np.where(init_temp > final_temp))] = 0\n",
    "# ## ^^ if weight moved toward 0, we just set it to 0\n",
    "#             freeze_init_value[i] = temp.reshape(initial_weights[i].shape)\n",
    "#             initial_weights[i] = freeze_init_value[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd34d596-2781-475c-aa86-ece956851452",
   "metadata": {},
   "source": [
    "# ––––––––––––"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82d77ad9-ee20-4714-aeb7-4da01511bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, val_loader, criterion, device):\n",
    "    val_losses = []\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(val_loader):\n",
    "\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            out = model(img)\n",
    "\n",
    "            loss_eval = criterion(out, label)\n",
    "            val_losses.append(loss_eval.item())\n",
    "\n",
    "            pred = out.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_acc = correct / ((len(val_loader) - 1) * BATCH_SIZE + label.size(0))\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da45ed94-79f3-4a2f-a703-688ad288c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## archived: initial 100 epoch training\n",
    "# def initial_train(model, train_loader, val_loader, optimizer, criterion, device):\n",
    "#     model.train()\n",
    "#     train_losses, val_losses = [], []\n",
    "#     val_accuracies = []\n",
    "#     for epoch in range(EPOCHS):\n",
    "\n",
    "#         print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "#         # compute val acc every epoch\n",
    "#         val_loss, val_acc = eval(model, val_loader, criterion, device)\n",
    "#         val_losses.append(val_loss)\n",
    "#         val_accuracies.append(val_acc)\n",
    "#         print(f\"Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.3f}\")\n",
    "#         model.train()\n",
    "\n",
    "#         for step, (img, label) in enumerate(train_loader):\n",
    "\n",
    "#             img, label = img.to(device), label.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             out = model(img)\n",
    "#             loss = criterion(out, label)\n",
    "#             train_losses.append(loss.item()) # every step\n",
    "#             loss.backward()\n",
    "\n",
    "#             # Monitoring overall gradient norm\n",
    "#             grads = [\n",
    "#                     param.grad.detach().flatten()\n",
    "#                     for param in model.parameters()\n",
    "#                     if param.grad is not None\n",
    "#                 ]\n",
    "#             norm = torch.cat(grads).norm()\n",
    "\n",
    "#             optimizer.step()\n",
    "\n",
    "#             if step % PRINT_ITERS == 0:\n",
    "#                 print(f\"Step: {step}/{len(train_loader)} | Running Average Loss: {np.mean(train_losses):.3f} | Grad Norm: {norm:.2f}\")\n",
    "\n",
    "#         torch.save(\n",
    "#             {\n",
    "#                 \"model_state_dict\": model.state_dict(),\n",
    "#                 \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "#             },\n",
    "#             f\"{path}/checkpoints/{MODEL_NAME}_EPOCH_{epoch+1}_SEED_{SEED}.pt\",\n",
    "#         )\n",
    "\n",
    "#         with open(\n",
    "#             f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_train_losses.json\", \"w\"\n",
    "#         ) as f:\n",
    "#             json.dump(train_losses, f)\n",
    "\n",
    "#         with open(\n",
    "#             f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_val_losses.json\", \"w\"\n",
    "#         ) as f2:\n",
    "#             json.dump(val_losses, f2)\n",
    "\n",
    "#         with open(\n",
    "#             f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_val_accuracies.json\", \"w\"\n",
    "#         ) as f3:\n",
    "#             json.dump(val_accuracies, f3)\n",
    "\n",
    "#     return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa1e076c-a6b4-42b3-9401-b36769cc2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_seed()\n",
    "# model = Net().to(device)\n",
    "# model.apply(init_params)\n",
    "\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # CPU: ~10 min/epoch, T4: ~45 sec\n",
    "# train_losses, val_losses, val_accuracies = initial_train(model, train_loader, val_loader, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68849d4b-f3b7-44ff-9937-04c143a795e8",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c2c00d7-f220-4409-8220-4a3be08881bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_train(model, train_loader, optimizer, criterion, model_pruned_pct, device):\n",
    "\n",
    "    print(f\"Training model with {model_pruned_pct:.2f}% pruned\")\n",
    "    model.train()\n",
    "    train_losses, val_losses = [], []\n",
    "    val_accuracies = []\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "        for step, (img, label) in enumerate(train_loader):\n",
    "\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(img)\n",
    "            loss = criterion(out, label)\n",
    "            train_losses.append(loss.item())  # every step\n",
    "            loss.backward()\n",
    "\n",
    "            # Monitoring overall gradient norm\n",
    "            grads = [\n",
    "                param.grad.detach().flatten()\n",
    "                for param in model.parameters()\n",
    "                if param.grad is not None\n",
    "            ]\n",
    "            norm = torch.cat(grads).norm()\n",
    "\n",
    "            # Disallow pruned weights from receiving gradient updates\n",
    "            for name, p in model.named_parameters():\n",
    "                if \"weight\" in name:\n",
    "                    p_data, p_grad = p.data.cpu().numpy(), p.grad.data.cpu().numpy()\n",
    "                    p_grad = np.where(np.abs(p_data) < EPS, 0, p_grad)\n",
    "                    p.grad.data = torch.from_numpy(p_grad).to(device)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            ####### TEMP\n",
    "            print(\"step ends after one, no evaluating val rn for debugging\")\n",
    "            if step == 0:\n",
    "                break\n",
    "\n",
    "            if step % PRINT_ITERS == 0:\n",
    "                print(\n",
    "                    f\"Step: {step}/{len(train_loader)} | Running Average Loss: {np.mean(train_losses):.3f} | Grad Norm: {norm:.2f}\"\n",
    "                )\n",
    "\n",
    "        # compute val acc at the end of every epoch\n",
    "\n",
    "        ####### TEMP COMMENTED OUT ALSO\n",
    "\n",
    "        # val_loss, val_acc = eval(model, val_loader, criterion, device)\n",
    "        # val_losses.append(val_loss)\n",
    "        # val_accuracies.append(val_acc)\n",
    "        # print(f\"Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.3f}\")\n",
    "        # model.train()\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            },\n",
    "            f\"{path}/checkpoints/{MODEL_NAME}_CURR_PRUNE_PCT_{model_pruned_pct:.0f}_EPOCH_{epoch+1}_SEED_{SEED}.pt\",\n",
    "        )\n",
    "\n",
    "        with open(\n",
    "            f\"{path}/train_logs/{MODEL_NAME}_CURR_PRUNE_PCT_{model_pruned_pct:.0f}_SEED_{SEED}_train_losses.json\",\n",
    "            \"w\",\n",
    "        ) as f:\n",
    "            json.dump(train_losses, f)\n",
    "\n",
    "        with open(\n",
    "            f\"{path}/train_logs/{MODEL_NAME}_CURR_PRUNE_PCT_{model_pruned_pct:.0f}_SEED_{SEED}_val_losses.json\",\n",
    "            \"w\",\n",
    "        ) as f2:\n",
    "            json.dump(val_losses, f2)\n",
    "\n",
    "        with open(\n",
    "            f\"{path}/train_logs/{MODEL_NAME}_CURR_PRUNE_PCT_{model_pruned_pct:.0f}_SEED_{SEED}_val_accuracies.json\",\n",
    "            \"w\",\n",
    "        ) as f3:\n",
    "            json.dump(val_accuracies, f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a05f23d-2ac3-404a-b8e3-e8a0606c5669",
   "metadata": {},
   "source": [
    "# Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8af7fdb2-84c0-44e9-8009-5bd2e78f1eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "LOAD_EPOCH = 100\n",
    "\n",
    "model, _ = get_model_and_optimizer()\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"{path}/checkpoints/{LOAD_MODEL_NAME}_EPOCH_{LOAD_EPOCH}_SEED_{SEED}.pt\",\n",
    "        map_location=device,\n",
    "    )[\"model_state_dict\"]\n",
    ")\n",
    "model.to(device)\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e82f1973-cf81-465a-8e14-38a1ff6ccac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = copy.deepcopy(model.state_dict())\n",
    "mask = generate_init_mask(model)\n",
    "\n",
    "layer_names = get_layer_weight_names(model)\n",
    "init_num_weight_params_by_layer = get_num_weight_params_by_layer(mask)\n",
    "init_num_weight_params = sum(init_num_weight_params_by_layer)\n",
    "\n",
    "# cannot use Adam——momentum stats cause frozen weights to continue to receive updates\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "# could also use SGD ig\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1caaea65-4e41-41f9-9811-197deb877b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_model_metrics = eval(model, val_loader, criterion, device)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    columns=[\"prune_iter\", \"pct_params\", \"pct_pruned\", \"val_loss\", \"val_acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d840dbf-8323-415c-b264-f98e664e6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### UNCOMMENT later\n",
    "\n",
    "## populate with original model\n",
    "# df.loc[0] = {\"prune_iter\": 0, \"pct_params\": 100.00, \"pct_pruned\": 0.00,\n",
    "#              \"val_loss\": orig_model_metrics[0], \"val_acc\": orig_model_metrics[1]}\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9c57e4c-8ce1-4367-96cf-070c075a113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "PRUNE_PCT = 80\n",
    "PRUNE_ITERS = 20\n",
    "PRUNE_ITER_PCT = (1 - ((1 - PRUNE_PCT / 100) ** (1 / PRUNE_ITERS))) * 100\n",
    "EPS = 1e-6\n",
    "PRINT_ITERS = 1  # frequency to print train loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dccfad2-bbc2-4c49-b81a-5f201092773a",
   "metadata": {},
   "source": [
    "# –––––––––"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69301a0e-767c-48ef-90e6-a51e8dc8038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prune Iteration 1/20\n",
      "Number of weight parameters: 1684443/1825600 ≈ 92.27%\n",
      "Weight breakdown:\n",
      "  conv1          : 1594/1728\n",
      "  conv2          : 68027/73728\n",
      "  conv3          : 272109/294912\n",
      "  conv4          : 1088438/1179648\n",
      "  batchnorm2d_1  : 118/128\n",
      "  batchnorm2d_2  : 472/512\n",
      "  fc1            : 241875/262144\n",
      "  fc2            : 11810/12800\n",
      "\n",
      "Training model with 7.73% pruned\n",
      "Epoch 1/1\n",
      "step ends after one, no evaluating val rn for debugging\n",
      "\n",
      "Prune Iteration 2/20\n",
      "Number of weight parameters: 1554198/1825600 ≈ 85.13%\n",
      "Weight breakdown:\n",
      "  conv1          : 1470/1728\n",
      "  conv2          : 62767/73728\n",
      "  conv3          : 251069/294912\n",
      "  conv4          : 1004280/1179648\n",
      "  batchnorm2d_1  : 108/128\n",
      "  batchnorm2d_2  : 435/512\n",
      "  fc1            : 223173/262144\n",
      "  fc2            : 10896/12800\n",
      "\n",
      "Training model with 14.87% pruned\n",
      "Epoch 1/1\n",
      "step ends after one, no evaluating val rn for debugging\n",
      "\n",
      "Prune Iteration 3/20\n",
      "Number of weight parameters: 1434024/1825600 ≈ 78.55%\n",
      "Weight breakdown:\n",
      "  conv1          : 1356/1728\n",
      "  conv2          : 57913/73728\n",
      "  conv3          : 231656/294912\n",
      "  conv4          : 926629/1179648\n",
      "  batchnorm2d_1  : 99/128\n",
      "  batchnorm2d_2  : 401/512\n",
      "  fc1            : 205917/262144\n",
      "  fc2            : 10053/12800\n",
      "\n",
      "Training model with 21.45% pruned\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# TRAIN HERE, for j iterations\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m################################################ TEMP COMMENTED OUT FOR DEBUGGING\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mprune_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_pruned_pct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# TODO: how to set j? simply train to convergence again?\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# evaluate and save statistics\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m## TEMP to avoid time consuming evaluation\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m, in \u001b[0;36mprune_train\u001b[0;34m(model, train_loader, optimizer, criterion, model_pruned_pct, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, label)\n\u001b[1;32m     17\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem()) \u001b[38;5;66;03m# every step\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Monitoring overall gradient norm\u001b[39;00m\n\u001b[1;32m     21\u001b[0m grads \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     22\u001b[0m         param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters()\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     ]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/self-learn/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/self-learn/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for prune_iter in range(PRUNE_ITERS):\n",
    "\n",
    "    print(f\"Prune Iteration {prune_iter+1}/{PRUNE_ITERS}\")\n",
    "\n",
    "    # prune\n",
    "    prune_by_percent(model, mask, PRUNE_ITER_PCT)\n",
    "\n",
    "    # reset remaining parameters to init state\n",
    "    reset_params(model, mask, init_state)\n",
    "\n",
    "    # log statistics\n",
    "    num_weight_params_by_layer = get_num_weight_params_by_layer(mask)\n",
    "    model_param_pct = (sum(num_weight_params_by_layer) / init_num_weight_params) * 100\n",
    "    model_pruned_pct = 100 - model_param_pct\n",
    "    print(\n",
    "        f\"Number of weight parameters: {sum(num_weight_params_by_layer)}/{init_num_weight_params} ≈ {model_param_pct:.2f}%\"\n",
    "    )\n",
    "\n",
    "    ## create list of proportion of surviving weights (as strings) (e.g. ['72/734', '49/626'])\n",
    "    params_props = [\n",
    "        f\"{num_weight_params_by_layer[i]}\"\n",
    "        + \"/\"\n",
    "        + f\"{init_num_weight_params_by_layer[i]}\"\n",
    "        for i in range(len(mask))\n",
    "    ]\n",
    "    print(\"Weight breakdown:\")\n",
    "    for i, name in enumerate(layer_names):\n",
    "        print(f\"  {name: <15}: {params_props[i]: <}\")\n",
    "    print()\n",
    "\n",
    "    # TRAIN HERE, for j iterations\n",
    "    ################################################ TEMP COMMENTED OUT FOR DEBUGGING\n",
    "    prune_train(model, train_loader, optimizer, criterion, model_pruned_pct, device)\n",
    "    print()\n",
    "\n",
    "    # TODO: how to set j? simply train to convergence again?\n",
    "\n",
    "    # evaluate and save statistics\n",
    "    # model_metrics = eval(model, val_loader, criterion, device)\n",
    "    # df.loc[prune_iter+1] = {\"prune_iter\": prune_iter+1, \"pct_params\": model_param_pct, \"pct_pruned\": model_pruned_pct,\n",
    "    #                         \"val_loss\": model_metrics[0], \"val_acc\": model_metrics[1]}\n",
    "\n",
    "    ## TEMP to avoid time consuming evaluation\n",
    "    df.loc[prune_iter + 1] = {\n",
    "        \"prune_iter\": prune_iter + 1,\n",
    "        \"pct_params\": model_param_pct,\n",
    "        \"pct_pruned\": model_pruned_pct,\n",
    "        \"val_loss\": 0.8172,\n",
    "        \"val_acc\": 0.487325,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5eba9-934b-407f-882d-e05cd7b2b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ab35a-baec-4d71-8baf-f5ebed42d8fe",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63287cc8-7d0a-4ede-a2b0-37f4c8e6744a",
   "metadata": {},
   "source": [
    "### Part I: Train vs. validation loss of differently pruned model size checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098b691-4c23-4a53-b1d3-b43535970b7c",
   "metadata": {},
   "source": [
    "### Part II: Validation accuracy across the pruned model checkpoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
