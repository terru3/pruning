{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5202ad22-3c0d-4105-a252-bdc13e42faae",
   "metadata": {},
   "source": [
    "# Pruning / LTH (CIFAR-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cf368c-b887-46de-8afe-f6273fae1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0e47a5-ef43-4648-a0be-b3c321766a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = None\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9621ac8-e70f-46bd-9a94-aa3dfb246a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15037760-5e85-4e1e-a228-ebb01f954baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "path = path if drive is None else \"/content/drive/MyDrive/self-learn/pruning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c53a791-c468-4836-838b-679842573e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e210a94-77eb-434d-9174-4e591d016470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from constants import *\n",
    "from utils import set_seed, train_data, val_data, \\\n",
    "                    train_loader, val_loader, fine_labels, invTrans\n",
    "from models import get_model_and_optimizer\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f847281-6cdb-4269-9fdf-57975d4aa9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: CNN_CIFAR_100_PRUNE_PCT_80\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = (\n",
    "    f\"CNN_CIFAR_100_PRUNE_PCT_{PRUNE_PCT}\"\n",
    ")\n",
    "print(\"Model Name:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "404fa4d3-2a09-4f14-8d54-6a20abbc7c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL_NAME = (\n",
    "    f\"CNN_CIFAR_100_PRUNE_PCT_0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80708e66-0e2f-4db2-82ec-b46d802f0ca3",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7920c1c4-6133-4ae8-b3c5-7432b769060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # expected: (BATCH_SIZE, 3, 32, 32), picture of mountain\n",
    "\n",
    "# batch = next(iter(train_loader))\n",
    "# print(batch[0].shape)\n",
    "# test_idx = 42\n",
    "# plt.imshow(batch[0][test_idx].permute(1,2,0))\n",
    "# plt.title(f'{fine_labels[batch[1][test_idx]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b42b08-84c7-47b6-a81d-09f66f414db0",
   "metadata": {},
   "source": [
    "# Pruning utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeff347f-6714-42d1-a114-41358b75b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(m):\n",
    "    \"\"\"\n",
    "    Initializes params for model `m` given Conv2d, BatchNorm1d,  BatchNorm2d, Linear layers.\n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.normal_(m.weight.data, mean=1, std=0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        nn.init.normal_(m.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf0ddb3-69d4-4589-971f-1888f77ee23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_params(m, mask, init_state):\n",
    "    \"\"\"\n",
    "    Resets surviving model parameters to initial values\n",
    "    \"\"\"\n",
    "    step = 0\n",
    "    for name, param in model.named_parameters(): \n",
    "        if \"weight\" in name: \n",
    "            param.data = torch.from_numpy(init_state[name].cpu().numpy() * mask[step]).to(param.device)\n",
    "            step += 1\n",
    "        if \"bias\" in name:\n",
    "            param.data = init_state[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb6f466f-7324-4678-a98a-f792571093fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_init_mask(m):\n",
    "    \"\"\"\n",
    "    Generates initial mask matching the shape of model parameters.\n",
    "    Returns:\n",
    "        -Mask: List of length matching the number of weight layers in `m`, each of shape matching the corresponding weight tensor.\n",
    "    \"\"\"\n",
    "    weight_params = [param.data.cpu().numpy() for (name, param) in model.named_parameters() if 'weight' in name]\n",
    "    # TODO: maybe don't do this——could be unnecessarily memory intensive?\n",
    "    # if so, revert back to prev method: sum of weight in name to get the length, then down below loop through actual model\n",
    "    mask = [None] * len(weight_params)\n",
    "    \n",
    "    step = 0\n",
    "    for param in weight_params:\n",
    "        mask[step] = np.ones_like(param)\n",
    "        step = step + 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "da1b8b19-cfd6-4f0a-838c-b3a287faf97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_weight_names(m):\n",
    "    \"\"\"\n",
    "    Returns a list of weight layer names of model `m`.\n",
    "    \"\"\"\n",
    "    layer_weight_names = []\n",
    "    for name, _ in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            layer_weight_names.append(name.split('.weight')[0])\n",
    "    return layer_weight_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "370a251a-883c-4341-9b10-6ff69858ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_weight_params_by_layer(mask):\n",
    "    \"\"\"\n",
    "    Returns number of surviving (nonzero) weight parameters in a pruned model via its binary mask, by layer.\n",
    "    \"\"\"\n",
    "    return [np.count_nonzero(mask[i]) for i in range(len(mask))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8054d353-b695-4d50-bc88-f4b3a6f039d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_by_percent(m, mask, pct):\n",
    "    \"\"\"\n",
    "    Prunes `pct`% of parameters of model `m`, and modifies the pruning mask in-place as well.\n",
    "    Specifically, this is done layerwise (p% of weights for each layer).\n",
    "    \"\"\"\n",
    "    assert isinstance(pct, (int, float)) and 0 <= pct and pct <= 100, \"`pct` must be a numeric value between 0 and 100 (inclusive).\"\n",
    "    step = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            p_data_all = param.data.cpu().numpy()\n",
    "            # flattened nonzero weights\n",
    "            p_data = p_data_all[np.nonzero(p_data_all)]\n",
    "    \n",
    "            cutoff_val = np.percentile(np.abs(p_data), pct) # percentile calculated on surviving params\n",
    "\n",
    "            new_mask = np.where(np.abs(p_data_all) < cutoff_val, 0, mask[step])\n",
    "            \n",
    "            param.data = torch.from_numpy(p_data_all * new_mask).to(param.device)\n",
    "            mask[step] = new_mask\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82d77ad9-ee20-4714-aeb7-4da01511bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, val_loader, criterion, device):\n",
    "    val_losses = []\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(val_loader):\n",
    "          \n",
    "            img, label = img.to(device), label.to(device)\n",
    "            out = model(img)\n",
    "            \n",
    "            loss_eval = criterion(out, label)\n",
    "            val_losses.append(loss_eval.item())\n",
    "            \n",
    "            pred = out.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_acc = correct / (len(val_loader) * BATCH_SIZE)\n",
    "    \n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da45ed94-79f3-4a2f-a703-688ad288c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## archived: initial 100 epoch training\n",
    "# def initial_train(model, train_loader, val_loader, optimizer, criterion, device):\n",
    "#     model.train()\n",
    "#     train_losses, val_losses = [], []\n",
    "#     val_accuracies = []\n",
    "#     for epoch in range(EPOCHS):\n",
    "        \n",
    "#         print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "#         # compute val acc every epoch\n",
    "#         val_loss, val_acc = eval(model, val_loader, criterion, device)\n",
    "#         val_losses.append(val_loss)\n",
    "#         val_accuracies.append(val_acc)\n",
    "#         print(f\"Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.3f}\")\n",
    "#         model.train()\n",
    "        \n",
    "#         for step, (img, label) in enumerate(train_loader):\n",
    "\n",
    "#             img, label = img.to(device), label.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             out = model(img)\n",
    "#             loss = criterion(out, label)\n",
    "#             train_losses.append(loss.item()) # every step\n",
    "#             loss.backward()\n",
    "    \n",
    "#             # Monitoring overall gradient norm\n",
    "#             grads = [\n",
    "#                     param.grad.detach().flatten()\n",
    "#                     for param in model.parameters()\n",
    "#                     if param.grad is not None\n",
    "#                 ]\n",
    "#             norm = torch.cat(grads).norm()\n",
    "            \n",
    "#             optimizer.step()\n",
    "            \n",
    "#             if step % PRINT_ITERS == 0:\n",
    "#                 print(f\"Step: {step}/{len(train_loader)} | Running Average Loss: {np.mean(train_losses):.3f} | Grad Norm: {norm:.2f}\")\n",
    "            \n",
    "#         torch.save(\n",
    "#             {\n",
    "#                 \"model_state_dict\": model.state_dict(),\n",
    "#                 \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "#             },\n",
    "#             f\"{path}/checkpoints/{MODEL_NAME}_EPOCH_{epoch+1}_SEED_{SEED}.pt\",\n",
    "#         )\n",
    "\n",
    "#         with open(\n",
    "#             f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_train_losses.json\", \"w\"\n",
    "#         ) as f:\n",
    "#             json.dump(train_losses, f)\n",
    "\n",
    "#         with open(\n",
    "#             f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_val_losses.json\", \"w\"\n",
    "#         ) as f2:\n",
    "#             json.dump(val_losses, f2)\n",
    "\n",
    "#         with open(\n",
    "#             f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_val_accuracies.json\", \"w\"\n",
    "#         ) as f3:\n",
    "#             json.dump(val_accuracies, f3)\n",
    "\n",
    "#     return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa1e076c-a6b4-42b3-9401-b36769cc2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_seed()\n",
    "# model = Net().to(device)\n",
    "# model.apply(init_params)\n",
    "\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # CPU: ~10 min/epoch, T4: ~45 sec\n",
    "# train_losses, val_losses, val_accuracies = initial_train(model, train_loader, val_loader, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68849d4b-f3b7-44ff-9937-04c143a795e8",
   "metadata": {},
   "source": [
    "# Pruning (to-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c2c00d7-f220-4409-8220-4a3be08881bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    train_losses, val_losses = [], []\n",
    "    val_accuracies = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "        # compute val acc every epoch\n",
    "        val_loss, val_acc = eval(model, val_loader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        print(f\"Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.3f}\")\n",
    "        model.train()\n",
    "\n",
    "        for i, (img, label) in enumerate(train_loader):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(img)\n",
    "            loss = criterion(out, label)\n",
    "            train_losses.append(loss.item()) # every step\n",
    "            loss.backward()\n",
    "    \n",
    "            # Monitoring overall gradient norm\n",
    "            grads = [\n",
    "                    param.grad.detach().flatten()\n",
    "                    for param in model.parameters()\n",
    "                    if param.grad is not None\n",
    "                ]\n",
    "            norm = torch.cat(grads).norm()\n",
    "            \n",
    "            # Disallow pruned weights from receiving gradient updates\n",
    "            for name, p in model.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    p_data, p_grad = p.data.cpu().numpy(), p.grad.data.cpu().numpy()\n",
    "                    grad_tensor = np.where(tensor < EPS, 0, grad_tensor)\n",
    "                    p.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % PRINT_ITERS == 0:\n",
    "                print(f\"Step: {step}/{len(train_loader)} | Running Average Loss: {np.mean(train_losses):.3f} | Grad Norm: {norm:.2f}\")\n",
    "            \n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            },\n",
    "            f\"{path}/checkpoints/{MODEL_NAME}_EPOCH_{epoch+1}_SEED_{SEED}.pt\",\n",
    "        )\n",
    "    \n",
    "        with open(\n",
    "            f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_train_losses.json\", \"w\"\n",
    "        ) as f:\n",
    "            json.dump(train_losses, f)\n",
    "    \n",
    "        with open(\n",
    "            f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_val_losses.json\", \"w\"\n",
    "        ) as f2:\n",
    "            json.dump(val_losses, f2)\n",
    "    \n",
    "        with open(\n",
    "            f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_val_accuracies.json\", \"w\"\n",
    "        ) as f3:\n",
    "            json.dump(val_accuracies, f3)\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a05f23d-2ac3-404a-b8e3-e8a0606c5669",
   "metadata": {},
   "source": [
    "# Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8af7fdb2-84c0-44e9-8009-5bd2e78f1eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "LOAD_EPOCH = 100\n",
    "\n",
    "model, _ = get_model_and_optimizer()\n",
    "model.load_state_dict(torch.load(f\"{path}/checkpoints/{LOAD_MODEL_NAME}_EPOCH_{LOAD_EPOCH}_SEED_{SEED}.pt\",\n",
    "                                  map_location=device)[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e82f1973-cf81-465a-8e14-38a1ff6ccac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = copy.deepcopy(model.state_dict())\n",
    "mask = generate_init_mask(model)\n",
    "\n",
    "layer_names = get_layer_weight_names(model)\n",
    "init_num_weight_params_by_layer = get_num_weight_params_by_layer(mask)\n",
    "init_num_weight_params = sum(init_num_weight_params_by_layer)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac81beb1-5d3a-4582-bbd0-cb75cbfbab2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6591883957386018, 0.56044921875)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(model, val_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c369a1-a53a-4261-b218-ebe4baad3b2f",
   "metadata": {},
   "source": [
    "## TEMP constants and unconfirmed code for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9c57e4c-8ce1-4367-96cf-070c075a113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "PRUNE_PCT = 80\n",
    "PRUNE_ITERS = 5\n",
    "PRUNE_ITER_PCT = ( 1 - ( (1 - PRUNE_PCT/100)**(1/PRUNE_ITERS) ) ) * 100\n",
    "EPS = 1e-7\n",
    "PRINT_ITERS = 5  # frequency to print train loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a24c54-acc9-4fd6-9d89-7a731fd1f7d8",
   "metadata": {},
   "source": [
    "# TODO: need to add arg to prune_train to take in model_param_pct and embed that into the model and losses saving name. AND BE SURE TO ROUND IT BEFORE USING IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "45f0ec2c-3e61-453d-973e-7e847366f88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param_pct = (1598351/init_num_weight_params)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b1f58e5f-e9ca-4387-a411-771afe30fc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.55209246275197"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_param_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "69301a0e-767c-48ef-90e6-a51e8dc8038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prune iteration 0:\n",
      "Number of weight parameters: 1825600/1825600\n",
      "Weight breakdown:\n",
      "  conv1          : 1728/1728\n",
      "  conv2          : 73728/73728\n",
      "  conv3          : 294912/294912\n",
      "  conv4          : 1179648/1179648\n",
      "  batchnorm2d_1  : 128/128\n",
      "  batchnorm2d_2  : 512/512\n",
      "  fc1            : 262144/262144\n",
      "  fc2            : 12800/12800\n",
      "Prune iteration 1:\n",
      "Number of weight parameters: 1825600/1825600\n",
      "Weight breakdown:\n",
      "  conv1          : 1728/1728\n",
      "  conv2          : 73728/73728\n",
      "  conv3          : 294912/294912\n",
      "  conv4          : 1179648/1179648\n",
      "  batchnorm2d_1  : 128/128\n",
      "  batchnorm2d_2  : 512/512\n",
      "  fc1            : 262144/262144\n",
      "  fc2            : 12800/12800\n",
      "Prune iteration 2:\n",
      "Number of weight parameters: 1825600/1825600\n",
      "Weight breakdown:\n",
      "  conv1          : 1728/1728\n",
      "  conv2          : 73728/73728\n",
      "  conv3          : 294912/294912\n",
      "  conv4          : 1179648/1179648\n",
      "  batchnorm2d_1  : 128/128\n",
      "  batchnorm2d_2  : 512/512\n",
      "  fc1            : 262144/262144\n",
      "  fc2            : 12800/12800\n",
      "Prune iteration 3:\n",
      "Number of weight parameters: 1825600/1825600\n",
      "Weight breakdown:\n",
      "  conv1          : 1728/1728\n",
      "  conv2          : 73728/73728\n",
      "  conv3          : 294912/294912\n",
      "  conv4          : 1179648/1179648\n",
      "  batchnorm2d_1  : 128/128\n",
      "  batchnorm2d_2  : 512/512\n",
      "  fc1            : 262144/262144\n",
      "  fc2            : 12800/12800\n",
      "Prune iteration 4:\n",
      "Number of weight parameters: 1825600/1825600\n",
      "Weight breakdown:\n",
      "  conv1          : 1728/1728\n",
      "  conv2          : 73728/73728\n",
      "  conv3          : 294912/294912\n",
      "  conv4          : 1179648/1179648\n",
      "  batchnorm2d_1  : 128/128\n",
      "  batchnorm2d_2  : 512/512\n",
      "  fc1            : 262144/262144\n",
      "  fc2            : 12800/12800\n"
     ]
    }
   ],
   "source": [
    "for prune_iter in range(PRUNE_ITERS):\n",
    "    \n",
    "    print(f\"Prune iteration {prune_iter}:\")\n",
    "    num_weight_params_by_layer = get_num_weight_params_by_layer(mask)\n",
    "    print(f\"Number of weight parameters: {sum(num_weight_params_by_layer)}/{init_num_weight_params}\")\n",
    "    model_param_pct = (sum(num_weight_params_by_layer)/init_num_weight_params)*100\n",
    "    # create list of proportion of surviving weights (as strings) (e.g. ['72/734', '49/626'])\n",
    "    params_props = [f\"{init_num_weight_params_by_layer[i]}\" + \"/\" + f\"{num_weight_params_by_layer[i]}\" for i in range(len(mask))]\n",
    "    print(\"Weight breakdown:\")\n",
    "    for i, name in enumerate(layer_names):\n",
    "        print(f\"  {name: <15}: {params_props[i]: <}\")\n",
    "    \n",
    "    # prune\n",
    "    prune_by_percent(model, mask, PRUNE_ITER_PCT)\n",
    "    \n",
    "    # reset remaining parameters to init state\n",
    "    reset_params(model, mask, init_state)\n",
    "    \n",
    "    # TRAIN HERE, for j iterations\n",
    "    # train_losses, val_losses, val_accuracies = prune_train(model, train_loader, optimizer, criterion, device)\n",
    "    \n",
    "    # TODO: how to set j? simply train to convergence again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5eba9-934b-407f-882d-e05cd7b2b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_accuracies = prune_train(model, train_loader, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ab35a-baec-4d71-8baf-f5ebed42d8fe",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63287cc8-7d0a-4ede-a2b0-37f4c8e6744a",
   "metadata": {},
   "source": [
    "### Part I: Train vs. validation loss of differently pruned model size checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098b691-4c23-4a53-b1d3-b43535970b7c",
   "metadata": {},
   "source": [
    "### Part II: Validation accuracy across the pruned model checkpoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
