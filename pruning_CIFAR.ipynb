{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5202ad22-3c0d-4105-a252-bdc13e42faae",
   "metadata": {},
   "source": [
    "# Pruning / LTH (CIFAR-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f4cf368c-b887-46de-8afe-f6273fae1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0e47a5-ef43-4648-a0be-b3c321766a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = None\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9621ac8-e70f-46bd-9a94-aa3dfb246a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15037760-5e85-4e1e-a228-ebb01f954baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "path = path if drive is None else \"/content/drive/MyDrive/self-learn/pruning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c53a791-c468-4836-838b-679842573e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e210a94-77eb-434d-9174-4e591d016470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from constants import *\n",
    "from utils import set_seed, train_data, val_data, \\\n",
    "                    train_loader, val_loader, fine_labels, invTrans\n",
    "from models import get_model_and_optimizer\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f847281-6cdb-4269-9fdf-57975d4aa9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: CNN_CIFAR_100_PRUNE_PCT_80\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = (\n",
    "    f\"CNN_CIFAR_100_PRUNE_PCT_{PRUNE_PCT}\"\n",
    ")\n",
    "print(\"Model Name:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "404fa4d3-2a09-4f14-8d54-6a20abbc7c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL_NAME = (\n",
    "    f\"CNN_CIFAR_100_PRUNE_PCT_0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80708e66-0e2f-4db2-82ec-b46d802f0ca3",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7920c1c4-6133-4ae8-b3c5-7432b769060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # expected: (BATCH_SIZE, 3, 32, 32), picture of mountain\n",
    "\n",
    "# batch = next(iter(train_loader))\n",
    "# print(batch[0].shape)\n",
    "# test_idx = 42\n",
    "# plt.imshow(batch[0][test_idx].permute(1,2,0))\n",
    "# plt.title(f'{fine_labels[batch[1][test_idx]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b42b08-84c7-47b6-a81d-09f66f414db0",
   "metadata": {},
   "source": [
    "# Pruning utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeff347f-6714-42d1-a114-41358b75b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(m):\n",
    "    \"\"\"\n",
    "    Initializes params for model `m` given Conv2d, BatchNorm1d,  BatchNorm2d, Linear layers.\n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.normal_(m.weight.data, mean=1, std=0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        nn.init.normal_(m.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf0ddb3-69d4-4589-971f-1888f77ee23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_params(m, mask, init_state):\n",
    "    \"\"\"\n",
    "    Resets surviving model parameters to initial values\n",
    "    \"\"\"\n",
    "    step = 0\n",
    "    for name, param in model.named_parameters(): \n",
    "        if \"weight\" in name: \n",
    "            param.data = torch.from_numpy(init_state[name].cpu().numpy() * mask[step]).to(param.device)\n",
    "            step += 1\n",
    "        if \"bias\" in name:\n",
    "            param.data = init_state[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb6f466f-7324-4678-a98a-f792571093fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_init_mask(m):\n",
    "    \"\"\"\n",
    "    Generates initial mask matching the shape of model parameters.\n",
    "    Returns:\n",
    "        -Mask: List of length matching the number of weight layers in `m`, each of shape matching the corresponding weight tensor.\n",
    "    \"\"\"\n",
    "    weight_params = [param.data.cpu().numpy() for (name, param) in model.named_parameters() if 'weight' in name]\n",
    "    # TODO: maybe don't do this——could be unnecessarily memory intensive?\n",
    "    # if so, revert back to prev method: sum of weight in name to get the length, then down below loop through actual model\n",
    "    mask = [None] * len(weight_params)\n",
    "    \n",
    "    step = 0\n",
    "    for param in weight_params:\n",
    "        mask[step] = np.ones_like(param)\n",
    "        step = step + 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da1b8b19-cfd6-4f0a-838c-b3a287faf97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_weight_names(m):\n",
    "    \"\"\"\n",
    "    Returns a list of weight layer names of model `m`.\n",
    "    \"\"\"\n",
    "    layer_weight_names = []\n",
    "    for name, _ in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            layer_weight_names.append(name.split('.weight')[0])\n",
    "    return layer_weight_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "370a251a-883c-4341-9b10-6ff69858ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_weight_params_by_layer(mask):\n",
    "    \"\"\"\n",
    "    Returns number of surviving (nonzero) weight parameters in a pruned model via its binary mask, by layer.\n",
    "    \"\"\"\n",
    "    return [np.count_nonzero(mask[i]) for i in range(len(mask))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8054d353-b695-4d50-bc88-f4b3a6f039d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_by_percent(m, mask, pct):\n",
    "    \"\"\"\n",
    "    Prunes `pct`% of parameters of model `m`, and modifies the pruning mask in-place as well.\n",
    "    Specifically, this is done layerwise (p% of weights for each layer).\n",
    "    \"\"\"\n",
    "    assert isinstance(pct, (int, float)) and 0 <= pct and pct <= 100, \"`pct` must be a numeric value between 0 and 100 (inclusive).\"\n",
    "    step = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            p_data_all = param.data.cpu().numpy()\n",
    "            # flattened nonzero weights\n",
    "            p_data = p_data_all[np.nonzero(p_data_all)]\n",
    "    \n",
    "            cutoff_val = np.percentile(np.abs(p_data), pct) # percentile calculated on surviving params\n",
    "\n",
    "            new_mask = np.where(np.abs(p_data_all) < cutoff_val, 0, mask[step])\n",
    "            \n",
    "            param.data = torch.from_numpy(p_data_all * new_mask).to(param.device)\n",
    "            mask[step] = new_mask\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82d77ad9-ee20-4714-aeb7-4da01511bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, val_loader, criterion, device):\n",
    "    val_losses = []\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(val_loader):\n",
    "          \n",
    "            img, label = img.to(device), label.to(device)\n",
    "            out = model(img)\n",
    "            \n",
    "            loss_eval = criterion(out, label)\n",
    "            val_losses.append(loss_eval.item())\n",
    "            \n",
    "            pred = out.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_acc = correct / (len(val_loader) * BATCH_SIZE)\n",
    "    \n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da45ed94-79f3-4a2f-a703-688ad288c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## archived: initial 100 epoch training\n",
    "# def initial_train(model, train_loader, val_loader, optimizer, criterion, device):\n",
    "#     model.train()\n",
    "#     train_losses, val_losses = [], []\n",
    "#     val_accuracies = []\n",
    "#     for epoch in range(EPOCHS):\n",
    "        \n",
    "#         print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "#         # compute val acc every epoch\n",
    "#         val_loss, val_acc = eval(model, val_loader, criterion, device)\n",
    "#         val_losses.append(val_loss)\n",
    "#         val_accuracies.append(val_acc)\n",
    "#         print(f\"Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.3f}\")\n",
    "#         model.train()\n",
    "        \n",
    "#         for step, (img, label) in enumerate(train_loader):\n",
    "\n",
    "#             img, label = img.to(device), label.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             out = model(img)\n",
    "#             loss = criterion(out, label)\n",
    "#             train_losses.append(loss.item()) # every step\n",
    "#             loss.backward()\n",
    "    \n",
    "#             # Monitoring overall gradient norm\n",
    "#             grads = [\n",
    "#                     param.grad.detach().flatten()\n",
    "#                     for param in model.parameters()\n",
    "#                     if param.grad is not None\n",
    "#                 ]\n",
    "#             norm = torch.cat(grads).norm()\n",
    "            \n",
    "#             optimizer.step()\n",
    "            \n",
    "#             if step % PRINT_ITERS == 0:\n",
    "#                 print(f\"Step: {step}/{len(train_loader)} | Running Average Loss: {np.mean(train_losses):.3f} | Grad Norm: {norm:.2f}\")\n",
    "            \n",
    "#         torch.save(\n",
    "#             {\n",
    "#                 \"model_state_dict\": model.state_dict(),\n",
    "#                 \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "#             },\n",
    "#             f\"{path}/checkpoints/{MODEL_NAME}_EPOCH_{epoch+1}_SEED_{SEED}.pt\",\n",
    "#         )\n",
    "\n",
    "#         with open(\n",
    "#             f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_train_losses.json\", \"w\"\n",
    "#         ) as f:\n",
    "#             json.dump(train_losses, f)\n",
    "\n",
    "#         with open(\n",
    "#             f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_val_losses.json\", \"w\"\n",
    "#         ) as f2:\n",
    "#             json.dump(val_losses, f2)\n",
    "\n",
    "#         with open(\n",
    "#             f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_val_accuracies.json\", \"w\"\n",
    "#         ) as f3:\n",
    "#             json.dump(val_accuracies, f3)\n",
    "\n",
    "#     return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa1e076c-a6b4-42b3-9401-b36769cc2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_seed()\n",
    "# model = Net().to(device)\n",
    "# model.apply(init_params)\n",
    "\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # CPU: ~10 min/epoch, T4: ~45 sec\n",
    "# train_losses, val_losses, val_accuracies = initial_train(model, train_loader, val_loader, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68849d4b-f3b7-44ff-9937-04c143a795e8",
   "metadata": {},
   "source": [
    "# Pruning (to-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c2c00d7-f220-4409-8220-4a3be08881bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_train(model, train_loader, optimizer, criterion, model_pruned_pct, device):\n",
    "    \n",
    "    print(f\"Training model with {model_pruned_pct:.2f}% pruned\")\n",
    "    model.train()\n",
    "    train_losses, val_losses = [], []\n",
    "    val_accuracies = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "        # compute val acc every epoch\n",
    "        val_loss, val_acc = eval(model, val_loader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        print(f\"Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.3f}\")\n",
    "        model.train()\n",
    "\n",
    "        for i, (img, label) in enumerate(train_loader):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(img)\n",
    "            loss = criterion(out, label)\n",
    "            train_losses.append(loss.item()) # every step\n",
    "            loss.backward()\n",
    "    \n",
    "            # Monitoring overall gradient norm\n",
    "            grads = [\n",
    "                    param.grad.detach().flatten()\n",
    "                    for param in model.parameters()\n",
    "                    if param.grad is not None\n",
    "                ]\n",
    "            norm = torch.cat(grads).norm()\n",
    "            \n",
    "            # Disallow pruned weights from receiving gradient updates\n",
    "            for name, p in model.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    p_data, p_grad = p.data.cpu().numpy(), p.grad.data.cpu().numpy()\n",
    "                    grad_tensor = np.where(tensor < EPS, 0, grad_tensor)\n",
    "                    p.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % PRINT_ITERS == 0:\n",
    "                print(f\"Step: {step}/{len(train_loader)} | Running Average Loss: {np.mean(train_losses):.3f} | Grad Norm: {norm:.2f}\")\n",
    "            \n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            },\n",
    "            f\"{path}/checkpoints/{MODEL_NAME}_CURR_PRUNE_PCT_{model_pruned_pct:.0f}_SEED_{SEED}.pt\",\n",
    "        )\n",
    "    \n",
    "        with open(\n",
    "            f\"{path}/train_logs/{MODEL_NAME}_CURR_PRUNE_PCT_{model_pruned_pct:.0f}_SEED_{SEED}_train_losses.json\", \"w\"\n",
    "        ) as f:\n",
    "            json.dump(train_losses, f)\n",
    "    \n",
    "        with open(\n",
    "            f\"{path}/train_logs/{MODEL_NAME}_CURR_PRUNE_PCT_{model_pruned_pct:.0f}_SEED_{SEED}_val_losses.json\", \"w\"\n",
    "        ) as f2:\n",
    "            json.dump(val_losses, f2)\n",
    "    \n",
    "        with open(\n",
    "            f\"{path}/train_logs/{MODEL_NAME}_CURR_PRUNE_PCT_{model_pruned_pct:.0f}_SEED_{SEED}_val_accuracies.json\", \"w\"\n",
    "        ) as f3:\n",
    "            json.dump(val_accuracies, f3)\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a05f23d-2ac3-404a-b8e3-e8a0606c5669",
   "metadata": {},
   "source": [
    "# Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8af7fdb2-84c0-44e9-8009-5bd2e78f1eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "LOAD_EPOCH = 100\n",
    "\n",
    "model, _ = get_model_and_optimizer()\n",
    "model.load_state_dict(torch.load(f\"{path}/checkpoints/{LOAD_MODEL_NAME}_EPOCH_{LOAD_EPOCH}_SEED_{SEED}.pt\",\n",
    "                                  map_location=device)[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e82f1973-cf81-465a-8e14-38a1ff6ccac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = copy.deepcopy(model.state_dict())\n",
    "mask = generate_init_mask(model)\n",
    "\n",
    "layer_names = get_layer_weight_names(model)\n",
    "init_num_weight_params_by_layer = get_num_weight_params_by_layer(mask)\n",
    "init_num_weight_params = sum(init_num_weight_params_by_layer)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1caaea65-4e41-41f9-9811-197deb877b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_model_metrics = eval(model, val_loader, criterion, device)\n",
    "\n",
    "df = pd.DataFrame(columns = [\"prune_iter\", \"pct_params\", \"pct_pruned\", \"val_loss\", \"val_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6d840dbf-8323-415c-b264-f98e664e6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### UNCOMMENT later\n",
    "\n",
    "## populate with original model\n",
    "# df.loc[0] = {\"prune_iter\": 0, \"pct_params\": 100.00, \"pct_pruned\": 0.00,\n",
    "#              \"val_loss\": orig_model_metrics[0], \"val_acc\": orig_model_metrics[1]}\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c369a1-a53a-4261-b218-ebe4baad3b2f",
   "metadata": {},
   "source": [
    "## TEMP constants and unconfirmed code for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e9c57e4c-8ce1-4367-96cf-070c075a113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "PRUNE_PCT = 80\n",
    "PRUNE_ITERS = 5\n",
    "PRUNE_ITER_PCT = ( 1 - ( (1 - PRUNE_PCT/100)**(1/PRUNE_ITERS) ) ) * 100\n",
    "EPS = 1e-7\n",
    "PRINT_ITERS = 5  # frequency to print train loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dccfad2-bbc2-4c49-b81a-5f201092773a",
   "metadata": {},
   "source": [
    "# –––––––––"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "69301a0e-767c-48ef-90e6-a51e8dc8038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prune Iteration 1/5\n",
      "Number of weight parameters: 1323156/1825600 ≈ 72.48%\n",
      "Weight breakdown:\n",
      "  conv1          : 1252/1728\n",
      "  conv2          : 53436/73728\n",
      "  conv3          : 213746/294912\n",
      "  conv4          : 854985/1179648\n",
      "  batchnorm2d_1  : 93/128\n",
      "  batchnorm2d_2  : 371/512\n",
      "  fc1            : 189996/262144\n",
      "  fc2            : 9277/12800\n",
      "\n",
      "Prune Iteration 2/5\n",
      "Number of weight parameters: 958996/1825600 ≈ 52.53%\n",
      "Weight breakdown:\n",
      "  conv1          : 907/1728\n",
      "  conv2          : 38729/73728\n",
      "  conv3          : 154919/294912\n",
      "  conv4          : 619676/1179648\n",
      "  batchnorm2d_1  : 67/128\n",
      "  batchnorm2d_2  : 269/512\n",
      "  fc1            : 137705/262144\n",
      "  fc2            : 6724/12800\n",
      "\n",
      "Prune Iteration 3/5\n",
      "Number of weight parameters: 695059/1825600 ≈ 38.07%\n",
      "Weight breakdown:\n",
      "  conv1          : 657/1728\n",
      "  conv2          : 28070/73728\n",
      "  conv3          : 112282/294912\n",
      "  conv4          : 449128/1179648\n",
      "  batchnorm2d_1  : 48/128\n",
      "  batchnorm2d_2  : 195/512\n",
      "  fc1            : 99806/262144\n",
      "  fc2            : 4873/12800\n",
      "\n",
      "Prune Iteration 4/5\n",
      "Number of weight parameters: 503763/1825600 ≈ 27.59%\n",
      "Weight breakdown:\n",
      "  conv1          : 476/1728\n",
      "  conv2          : 20344/73728\n",
      "  conv3          : 81379/294912\n",
      "  conv4          : 325519/1179648\n",
      "  batchnorm2d_1  : 35/128\n",
      "  batchnorm2d_2  : 141/512\n",
      "  fc1            : 72337/262144\n",
      "  fc2            : 3532/12800\n",
      "\n",
      "Prune Iteration 5/5\n",
      "Number of weight parameters: 365117/1825600 ≈ 20.00%\n",
      "Weight breakdown:\n",
      "  conv1          : 345/1728\n",
      "  conv2          : 14745/73728\n",
      "  conv3          : 58982/294912\n",
      "  conv4          : 235930/1179648\n",
      "  batchnorm2d_1  : 25/128\n",
      "  batchnorm2d_2  : 102/512\n",
      "  fc1            : 52428/262144\n",
      "  fc2            : 2560/12800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for prune_iter in range(PRUNE_ITERS):\n",
    "    \n",
    "    print(f\"Prune Iteration {prune_iter+1}/{PRUNE_ITERS}\")\n",
    "    \n",
    "    # prune\n",
    "    prune_by_percent(model, mask, PRUNE_ITER_PCT)\n",
    "    \n",
    "    # reset remaining parameters to init state\n",
    "    reset_params(model, mask, init_state)\n",
    "\n",
    "    # log statistics\n",
    "    num_weight_params_by_layer = get_num_weight_params_by_layer(mask)\n",
    "    model_param_pct = (sum(num_weight_params_by_layer)/init_num_weight_params)*100\n",
    "    model_pruned_pct = 100 - model_param_pct\n",
    "    print(f\"Number of weight parameters: {sum(num_weight_params_by_layer)}/{init_num_weight_params} ≈ {model_param_pct:.2f}%\")\n",
    "    \n",
    "    ## create list of proportion of surviving weights (as strings) (e.g. ['72/734', '49/626'])\n",
    "    params_props = [f\"{num_weight_params_by_layer[i]}\" + \"/\" + f\"{init_num_weight_params_by_layer[i]}\" for i in range(len(mask))]\n",
    "    print(\"Weight breakdown:\")\n",
    "    for i, name in enumerate(layer_names):\n",
    "        print(f\"  {name: <15}: {params_props[i]: <}\")\n",
    "    print()\n",
    "        \n",
    "    # TRAIN HERE, for j iterations\n",
    "    # train_losses, val_losses, val_accuracies = prune_train(model, train_loader, optimizer, criterion, model_pruned_pct, device)\n",
    "\n",
    "    # TODO: how to set j? simply train to convergence again?\n",
    "\n",
    "    # evaluate and save statistics\n",
    "    # model_metrics = eval(model, val_loader, criterion, device)\n",
    "    # df.loc[prune_iter+1] = {\"prune_iter\": prune_iter+1, \"pct_params\": model_param_pct, \"pct_pruned\": model_pruned_pct,\n",
    "    #                         \"val_loss\": model_metrics[0], \"val_acc\": model_metrics[1]}\n",
    "    \n",
    "    ## TEMP to avoid time consuming evaluation\n",
    "    df.loc[prune_iter+1] = {\"prune_iter\": prune_iter+1, \"pct_params\": model_param_pct, \"pct_pruned\": model_pruned_pct,\n",
    "                            \"val_loss\": 0.8172, \"val_acc\": 0.487325}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47d5eba9-934b-407f-882d-e05cd7b2b473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prune_iter</th>\n",
       "      <th>pct_params</th>\n",
       "      <th>pct_pruned</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>72.477870</td>\n",
       "      <td>27.522130</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.487325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>52.530456</td>\n",
       "      <td>47.469544</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.487325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38.072908</td>\n",
       "      <td>61.927092</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.487325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>27.594380</td>\n",
       "      <td>72.405620</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.487325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>19.999836</td>\n",
       "      <td>80.000164</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.487325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prune_iter  pct_params  pct_pruned  val_loss   val_acc\n",
       "1           1   72.477870   27.522130    0.8172  0.487325\n",
       "2           2   52.530456   47.469544    0.8172  0.487325\n",
       "3           3   38.072908   61.927092    0.8172  0.487325\n",
       "4           4   27.594380   72.405620    0.8172  0.487325\n",
       "5           5   19.999836   80.000164    0.8172  0.487325"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ab35a-baec-4d71-8baf-f5ebed42d8fe",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63287cc8-7d0a-4ede-a2b0-37f4c8e6744a",
   "metadata": {},
   "source": [
    "### Part I: Train vs. validation loss of differently pruned model size checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098b691-4c23-4a53-b1d3-b43535970b7c",
   "metadata": {},
   "source": [
    "### Part II: Validation accuracy across the pruned model checkpoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
