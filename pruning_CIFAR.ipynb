{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5202ad22-3c0d-4105-a252-bdc13e42faae",
   "metadata": {},
   "source": [
    "# Pruning / LTH (CIFAR-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cf368c-b887-46de-8afe-f6273fae1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0e47a5-ef43-4648-a0be-b3c321766a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = None\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9621ac8-e70f-46bd-9a94-aa3dfb246a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15037760-5e85-4e1e-a228-ebb01f954baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "path = path if drive is None else \"/content/drive/MyDrive/self-learn/pruning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c53a791-c468-4836-838b-679842573e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e210a94-77eb-434d-9174-4e591d016470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from constants import *\n",
    "from utils import set_seed, train_data, val_data, \\\n",
    "                    train_loader, val_loader, fine_labels\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f847281-6cdb-4269-9fdf-57975d4aa9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: CNN_CIFAR_100_PRUNE_PCT_0\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = (\n",
    "    f\"CNN_CIFAR_100_PRUNE_PCT_{PRUNE_PCT}\"\n",
    ")\n",
    "print(\"Model Name:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80708e66-0e2f-4db2-82ec-b46d802f0ca3",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7920c1c4-6133-4ae8-b3c5-7432b769060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # expected: (BATCH_SIZE, 3, 32, 32), picture of mountain\n",
    "\n",
    "# batch = next(iter(train_loader))\n",
    "# print(batch[0].shape)\n",
    "# test_idx = 42\n",
    "# plt.imshow(batch[0][test_idx].permute(1,2,0))\n",
    "# plt.title(f'{fine_labels[batch[1][test_idx]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c5a772b-b780-4059-98f5-84687463d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, 1)\n",
    "        self.conv4 = nn.Conv2d(256, 512, 3, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.batchnorm2d_1 = nn.BatchNorm2d(128)\n",
    "        self.batchnorm2d_2 = nn.BatchNorm2d(512)\n",
    "        self.fc1 = nn.Linear(512*2*2, 128)\n",
    "        self.fc2 = nn.Linear(128, 100) # 100 classes for fine labels\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.batchnorm2d_1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.batchnorm2d_2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc2(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b42b08-84c7-47b6-a81d-09f66f414db0",
   "metadata": {},
   "source": [
    "# Pruning utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeff347f-6714-42d1-a114-41358b75b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(m):\n",
    "    \"\"\"\n",
    "    Initializes params for model `m` given Conv2d, BatchNorm1d,  BatchNorm2d, Linear layers.\n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.normal_(m.weight.data, mean=1, std=0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.normal_(m.weight.data, mean=1, std=0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        nn.init.normal_(m.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf0ddb3-69d4-4589-971f-1888f77ee23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_params(m, mask, init_state):\n",
    "    \"\"\"\n",
    "    Resets surviving model parameters to initial values\n",
    "    \"\"\"\n",
    "    step = 0\n",
    "    for name, param in model.named_parameters(): \n",
    "        if \"weight\" in name: \n",
    "            param.data = torch.from_numpy(init_state[name].cpu().numpy() * mask[step]).to(param.device)\n",
    "            step += 1\n",
    "        if \"bias\" in name:\n",
    "            param.data = init_state[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb6f466f-7324-4678-a98a-f792571093fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_init_mask(m):\n",
    "    \"\"\"\n",
    "    Generates initial mask matching the shape of model parameters.\n",
    "    Returns:\n",
    "        -Mask: List of length matching the number of weight layers in `m`, each of shape matching the corresponding weight tensor.\n",
    "    \"\"\"\n",
    "    weight_params = [param.data.cpu().numpy() for (name, param) in model.named_parameters() if 'weight' in name]\n",
    "    # TODO: maybe don't do this——could be unnecessarily memory intensive?\n",
    "    # if so, revert back to prev method: sum of weight in name to get the length, then down below loop through actual model\n",
    "    mask = [None] * len(weight_params)\n",
    "    \n",
    "    step = 0\n",
    "    for param in weight_params:\n",
    "        mask[step] = np.ones_like(param)\n",
    "        step = step + 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8054d353-b695-4d50-bc88-f4b3a6f039d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_by_percent(m, mask, pct):\n",
    "    \"\"\"\n",
    "    Prunes `pct`% of parameters of model `m`, and modifies the pruning mask in-place as well.\n",
    "    Specifically, this is done layerwise (p% of weights for each layer).\n",
    "    \"\"\"\n",
    "    assert isinstance(pct, (int, float)) and 0 <= pct and pct <= 100, \"`pct` must be a numeric value between 0 and 100 (inclusive).\"\n",
    "    step = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            p_data_all = param.data.cpu().numpy()\n",
    "            # flattened nonzero weights\n",
    "            p_data = p_data_all[np.nonzero(p_data_all)]\n",
    "    \n",
    "            cutoff_val = np.percentile(np.abs(p_data_all), pct)\n",
    "\n",
    "            new_mask = np.where(np.abs(p_data_all) < cutoff_val, 0, mask[step])\n",
    "            \n",
    "            param.data = torch.from_numpy(p_data_all * new_mask).to(param.device)\n",
    "            mask[step] = new_mask\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c563de37-02ca-4cdb-beba-af0cbf6c095f",
   "metadata": {},
   "source": [
    "# Initial Training (for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da45ed94-79f3-4a2f-a703-688ad288c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_train(model, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_losses, val_losses = [], []\n",
    "    val_accuracies = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "        # compute val acc every epoch\n",
    "        val_loss, val_acc = eval(epoch)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        print(f\"Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.3f}\")\n",
    "        model.train()\n",
    "        \n",
    "        for step, (img, label) in enumerate(train_loader):\n",
    "\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(img)\n",
    "            loss = criterion(out, label)\n",
    "            train_losses.append(loss.item()) # every step\n",
    "            loss.backward()\n",
    "    \n",
    "            # Monitoring overall gradient norm\n",
    "            grads = [\n",
    "                    param.grad.detach().flatten()\n",
    "                    for param in model.parameters()\n",
    "                    if param.grad is not None\n",
    "                ]\n",
    "            norm = torch.cat(grads).norm()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % PRINT_ITERS == 0:\n",
    "                print(f\"Step: {step}/{len(train_loader)} | Running Average Loss: {np.mean(train_losses):.3f} | Grad Norm: {norm:.2f}\")\n",
    "            \n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            },\n",
    "            f\"{path}/checkpoints/{MODEL_NAME}_EPOCH_{epoch+1}_SEED_{SEED}.pt\",\n",
    "        )\n",
    "\n",
    "        with open(\n",
    "            f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_train_losses.json\", \"w\"\n",
    "        ) as f:\n",
    "            json.dump(train_losses, f)\n",
    "\n",
    "        with open(\n",
    "            f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_val_losses.json\", \"w\"\n",
    "        ) as f2:\n",
    "            json.dump(val_losses, f2)\n",
    "\n",
    "        with open(\n",
    "            f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_val_accuracies.json\", \"w\"\n",
    "        ) as f3:\n",
    "            json.dump(val_accuracies, f3)\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7c26eef-743f-48a1-ba71-f11e04cd4959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(epoch):\n",
    "    val_losses = []\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img, label in val_loader:\n",
    "            \n",
    "            img, label = img.to(device), label.to(device)\n",
    "            out = model(img)\n",
    "            \n",
    "            loss_eval = criterion(out, label)\n",
    "            val_losses.append(loss_eval.item())\n",
    "            \n",
    "            pred = out.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_acc = correct / (len(val_loader) * BATCH_SIZE)\n",
    "    \n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa1e076c-a6b4-42b3-9401-b36769cc2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = Net().to(device)\n",
    "model.apply(init_params)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9ba82-cb55-476e-bbd4-9d5cdd894fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU: ~10 min/epoch, T4: ~45 sec\n",
    "train_losses, val_losses, val_accuracies = initial_train(model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4740e7-b88d-4a56-b5a9-dc58553adad5",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a9453f5-f2d7-4b38-bb83-3b370ad016f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and optimizer loaded\n",
      "Losses, accuracies loaded\n"
     ]
    }
   ],
   "source": [
    "LOAD_EPOCH = 100\n",
    "\n",
    "model = Net()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "model.load_state_dict(torch.load(f\"{path}/checkpoints/{MODEL_NAME}_EPOCH_{LOAD_EPOCH}_SEED_{SEED}.pt\",\n",
    "                                  map_location=device)[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(torch.load(f\"{path}/checkpoints/{MODEL_NAME}_EPOCH_{LOAD_EPOCH}_SEED_{SEED}.pt\",\n",
    "                                  map_location=device)[\"optimizer_state_dict\"])\n",
    "model.to(device)\n",
    "print('Model and optimizer loaded')\n",
    "\n",
    "with open(\n",
    "    f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_train_losses.json\", \"r\"\n",
    ") as f:\n",
    "    train_losses = json.load(f)\n",
    "\n",
    "with open(\n",
    "    f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_val_losses.json\", \"r\"\n",
    ") as f2:\n",
    "    val_losses = json.load(f2)\n",
    "\n",
    "with open(\n",
    "    f\"{path}/train_logs/{MODEL_NAME}_SEED_{SEED}_val_accuracies.json\", \"r\"\n",
    ") as f3:\n",
    "    val_accuracies = json.load(f3)\n",
    "\n",
    "print(\"Losses, accuracies loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68849d4b-f3b7-44ff-9937-04c143a795e8",
   "metadata": {},
   "source": [
    "# Pruning (to-do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d7bc9-4d7e-4535-b298-fb448b545453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note this begins with pruning immediately and assumes a trained model as input\n",
    "\n",
    "# # Iterative pruning loop\n",
    "# for prune_iter in range(PRUNE_ITERS):\n",
    "#     # prune\n",
    "#     prune_by_percent(model, mask, PRUNE_ITER_PCT)\n",
    "#     # reset remaining parameters to init state\n",
    "#     reset_params(model, mask, init_state)\n",
    "#     # LOGGING——loss, accuracies, pct pruned, etc.\n",
    "#     # TRAIN HERE, for j iterations\n",
    "#     # TODO: how to set j? simply train to convergence again?\n",
    "#     # log % of model parameters, % of model size in bytes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c2c00d7-f220-4409-8220-4a3be08881bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_losses, val_losses = [], []\n",
    "    val_accuracies = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "        for i, (img, label) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            out = model(img)\n",
    "            loss = criterion(out, label)\n",
    "            train_losses.append(loss.item()) # every step\n",
    "            loss.backward()\n",
    "    \n",
    "            # Monitoring overall gradient norm\n",
    "            grads = [\n",
    "                    param.grad.detach().flatten()\n",
    "                    for param in model.parameters()\n",
    "                    if param.grad is not None\n",
    "                ]\n",
    "            norm = torch.cat(grads).norm()\n",
    "            \n",
    "            # Disallow pruned weights from receiving gradient updates\n",
    "            for name, p in model.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    p_data, p_grad = p.data.cpu().numpy(), p.grad.data.cpu().numpy()\n",
    "                    grad_tensor = np.where(tensor < EPS, 0, grad_tensor)\n",
    "                    p.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "            \n",
    "            if i % 50 == 0:\n",
    "                val_loss, val_acc = eval(epoch, i)\n",
    "                val_losses.append(val_loss)\n",
    "                val_accuracies.append(val_acc)\n",
    "                print(f\"Step: {i}/{len(train_loader)}, Running Average Loss: {np.mean(train_losses):.3f} |\",\n",
    "                      f\"Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.3f} | Grad Norm: {norm:.2f}\")\n",
    "                \n",
    "            optimizer.step()\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a05f23d-2ac3-404a-b8e3-e8a0606c5669",
   "metadata": {},
   "source": [
    "# Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d31eeffb-be1a-4d3a-bdca-d9a3e55639eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = copy.deepcopy(model.state_dict())\n",
    "mask = generate_init_mask(model)\n",
    "\n",
    "# apply pruning from earlier, see pseudocode\n",
    "\n",
    "# new optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5eba9-934b-407f-882d-e05cd7b2b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_accuracies = train(model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ab35a-baec-4d71-8baf-f5ebed42d8fe",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63287cc8-7d0a-4ede-a2b0-37f4c8e6744a",
   "metadata": {},
   "source": [
    "### Part I: Train vs. validation loss of differently pruned model size checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098b691-4c23-4a53-b1d3-b43535970b7c",
   "metadata": {},
   "source": [
    "### Part II: Validation accuracy across the pruned model checkpoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
